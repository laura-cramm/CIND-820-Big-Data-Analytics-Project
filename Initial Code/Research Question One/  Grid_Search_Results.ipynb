{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTmHWWeAZO_f"
      },
      "outputs": [],
      "source": [
        "logRegScores1 = pd.read_pickle(\"logRegScores1.pickle\")\n",
        "f2_scoreNB1 = pd.read_pickle(\"f2_scoreNB1.pickle\")\n",
        "rfScores1 = pd.read_pickle(\"rfScores1.pickle\")\n",
        "bstScores1 = pd.read_pickle(\"bstScores1.pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logRegScores2 = pd.read_pickle(\"logRegScores2.pickle\")\n",
        "f2_scoreNB2 = pd.read_pickle(\"f2_scoreNB2.pickle\")\n",
        "rfScores2 = pd.read_pickle(\"rfScores2.pickle\")\n",
        "bstScores2 = pd.read_pickle(\"bstScores2.pickle\")"
      ],
      "metadata": {
        "id": "CwxsrYOAZ6lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logRegScores3 = pd.read_pickle(\"logRegScores3.pickle\")\n",
        "f2_scoreNB3 = pd.read_pickle(\"f2_scoreNB3.pickle\")\n",
        "rfScores3 = pd.read_pickle(\"rfScores3.pickle\")\n",
        "bstScores3 = pd.read_pickle(\"bstScores3.pickle\")"
      ],
      "metadata": {
        "id": "c8t1g8bTaAGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logRegScores4 = pd.read_pickle(\"logRegScores4.pickle\")\n",
        "f2_scoreNB4 = pd.read_pickle(\"f2_scoreNB4.pickle\")\n",
        "rfScores4 = pd.read_pickle(\"rfScores4.pickle\")\n",
        "bstScores4 = pd.read_pickle(\"bstScores4.pickle\")"
      ],
      "metadata": {
        "id": "CmdqpirCaEXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logRegScores5 = pd.read_pickle(\"logRegScores5.pickle\")\n",
        "f2_scoreNB5 = pd.read_pickle(\"f2_scoreNB5.pickle\")\n",
        "rfScores5 = pd.read_pickle(\"rfScores5.pickle\")\n",
        "bstScores5 = pd.read_pickle(\"bstScores5.pickle\")"
      ],
      "metadata": {
        "id": "YAzuKoyAaIVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "XcVWH4Sta7dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logRegScores1 = logRegScores1.drop(['Unnamed: 0'], axis=1)\n",
        "logRegScores2 = logRegScores2.drop(['Unnamed: 0'], axis=1)\n",
        "logRegScores3 = logRegScores3.drop(['Unnamed: 0'], axis=1)\n",
        "logRegScores4 = logRegScores4.drop(['Unnamed: 0'], axis=1)\n",
        "logRegScores5 = logRegScores5.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "JjhFcM-x_e3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_logRegA = logRegScores1.merge(logRegScores2,on=['Solver'], suffixes=('_x1', '_x2'))\n",
        "merged_logRegB = merged_logRegA.merge(logRegScores3,on=['Solver'])\n",
        "merged_logRegC = merged_logRegB.merge(logRegScores4,on=['Solver'], suffixes=('_x3', '_x4'))\n",
        "merged_logReg = merged_logRegC.merge(logRegScores5,on=['Solver'])\n",
        "merged_logReg.rename(columns={'F2_Score': 'F2_Score_x5'}, inplace=True)"
      ],
      "metadata": {
        "id": "yKClRoyw_f8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing median F-2 Score across all five sliding windows for each combination\n",
        "#of hyperparameters\n",
        "for i in range(len(merged_logReg['F2_Score_x1'])):\n",
        "      merged_logReg.loc[merged_logReg.index[i], 'Median_Score'] = statistics.median([merged_logReg.loc[merged_logReg.index[i], 'F2_Score_x1'],merged_logReg.loc[merged_logReg.index[i], 'F2_Score_x2'], merged_logReg.loc[merged_logReg.index[i], 'F2_Score_x3'], merged_logReg.loc[merged_logReg.index[i], 'F2_Score_x4'], merged_logReg.loc[merged_logReg.index[i], 'F2_Score_x5']] )\n",
        "\n",
        "merged_logReg.sort_values(\"Median_Score\", ascending=False, inplace=True)\n",
        "merged_logReg\n",
        "\n",
        "#The optimal hyperparameter is Solver=liblinear"
      ],
      "metadata": {
        "id": "6J7JAkbq_hUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "_qisE9xtbMJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NB_score_list = [f2_scoreNB1, f2_scoreNB2, f2_scoreNB3, f2_scoreNB4, f2_scoreNB5]\n",
        "NB_score_list.sort(ascending=False)\n",
        "#Naive Bayes does not have any hyperparameters to optimize\n",
        "#(The F2-Scores were just investigated out of interest)"
      ],
      "metadata": {
        "id": "H4uEjH47_x5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "G7Sm6Z_dbeSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfScores1 = rfScores1.drop(['Unnamed: 0'], axis=1)\n",
        "rfScores2 = rfScores2.drop(['Unnamed: 0'], axis=1)\n",
        "rfScores3 = rfScores3.drop(['Unnamed: 0'], axis=1)\n",
        "rfScores4 = rfScores4.drop(['Unnamed: 0'], axis=1)\n",
        "rfScores5 = rfScores5.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "2VFWNt61_l2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_rfA = rfScores1.merge(rfScores2,on=['n_Estimators', 'Max_depth', 'Criterion'], suffixes=('_x1', '_x2'))\n",
        "merged_rfB = merged_rfA.merge(rfScores3,on=['n_Estimators', 'Max_depth', 'Criterion'])\n",
        "merged_rfC = merged_rfB.merge(rfScores4,on=['n_Estimators', 'Max_depth', 'Criterion'], suffixes=('_x3', '_x4'))\n",
        "merged_rf = merged_rfC.merge(rfScores5,on=['n_Estimators', 'Max_depth', 'Criterion'])\n",
        "merged_rf.rename(columns={'F2_Score': 'F2_Score_x5'}, inplace=True)"
      ],
      "metadata": {
        "id": "ELCM7CPJ_nAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing median F-2 Score across all five sliding windows for each combination\n",
        "#of hyperparameters\n",
        "for i in range(len(merged_rf['F2_Score_x1'])):\n",
        "      merged_rf.loc[merged_rf.index[i], 'Median_Score'] = statistics.median([merged_rf.loc[merged_rf.index[i], 'F2_Score_x1'],merged_rf.loc[merged_rf.index[i], 'F2_Score_x2'], merged_rf.loc[merged_rf.index[i], 'F2_Score_x3'], merged_rf.loc[merged_rf.index[i], 'F2_Score_x4'], merged_rf.loc[merged_rf.index[i], 'F2_Score_x5']] )\n",
        "\n",
        "merged_rf.sort_values(\"Median_Score\", ascending=False, inplace=True)\n",
        "merged_rf\n",
        "\n",
        "#The optimal hyperparameters are n_Estimators=100, max_depth=1, and criterion=\"log_loss\""
      ],
      "metadata": {
        "id": "I3cKxVVy_oHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Gradient-Boosted Trees"
      ],
      "metadata": {
        "id": "Q0qhn-J7by6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bstScores1 = bstScores1.drop(['Unnamed: 0'], axis=1)\n",
        "bstScores2 = bstScores2.drop(['Unnamed: 0'], axis=1)\n",
        "bstScores3 = bstScores3.drop(['Unnamed: 0'], axis=1)\n",
        "bstScores4 = bstScores4.drop(['Unnamed: 0'], axis=1)\n",
        "bstScores5 = bstScores5.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "tL4ghoxj_Ooo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_bstA = bstScores1.merge(bstScores2,on=['n_Estimators', 'Max_depth', 'Subsample'], suffixes=('_x1', '_x2'))\n",
        "merged_bstB = merged_bstA.merge(bstScores3,on=['n_Estimators', 'Max_depth', 'Subsample'])\n",
        "merged_bstC = merged_bstB.merge(bstScores4,on=['n_Estimators', 'Max_depth', 'Subsample'], suffixes=('_x3', '_x4'))\n",
        "merged_bst = merged_bstC.merge(bstScores5,on=['n_Estimators', 'Max_depth', 'Subsample'])\n",
        "merged_bst.rename(columns={'F2_Score': 'F2_Score_x5'}, inplace=True)"
      ],
      "metadata": {
        "id": "LokSaM0C_P-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing median F-2 Score across all five sliding windows for each combination\n",
        "#of hyperparameters\n",
        "for i in range(len(merged_bst['F2_Score_x1'])):\n",
        "      merged_bst.loc[merged_bst.index[i], 'Median_Score'] = statistics.median([merged_bst.loc[merged_bst.index[i], 'F2_Score_x1'],merged_bst.loc[merged_bst.index[i], 'F2_Score_x2'], merged_bst.loc[merged_bst.index[i], 'F2_Score_x3'], merged_bst.loc[merged_bst.index[i], 'F2_Score_x4'], merged_bst.loc[merged_bst.index[i], 'F2_Score_x5']] )\n",
        "\n",
        "merged_bst.sort_values(\"Median_Score\", ascending=False, inplace=True)\n",
        "merged_bst\n",
        "\n",
        "#The optimal hyperparameters are n_Estimators=25, max_depth=1, and subsample=0.2"
      ],
      "metadata": {
        "id": "1h-zo_4__TYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
