{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEhL/W0/FenNazxblP3z7M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CbVY3pDp879G"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from statsmodels.stats.outliers_influence import variance_inflation_factor"]},{"cell_type":"code","source":["q1features_train_2 = pd.read_pickle(\"q1features_train_2.pickle\")\n","q1features_valid_2 = pd.read_pickle(\"q1features_valid_2.pickle\")\n","q1target_train_2 = pd.read_pickle(\"q1target_train_2.pickle\")\n","q1target_valid_2 = pd.read_pickle(\"q1target_valid_2.pickle\")"],"metadata":{"id":"vl1KFwya9c_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Imputing validation set\n","for col in q1features_valid_2.columns.tolist():\n","  q1features_valid_2[col] = q1features_valid_2[col].replace([None], np.nan)\n","  if (q1features_valid_2[col].dtype == 'category' or q1features_valid_2[col].dtype =='datetime64[ns]'):\n","    q1features_valid_2[col]= q1features_valid_2[col].fillna(q1features_train_2[col].mode()[0])\n","  if (q1features_valid_2[col].dtype == 'Int64' or q1features_valid_2[col].dtype == 'int64'):\n","    q1features_valid_2[col] = q1features_valid_2[col].astype('float64')\n","  if (q1features_valid_2[col].dtype == 'float64'):\n","    q1features_valid_2[col] = q1features_valid_2[col].fillna(q1features_train_2[col].mean())"],"metadata":{"id":"GCOuM7ii9tnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Imputing training set\n","for col in q1features_train_2.columns.tolist():\n","  q1features_train_2[col] = q1features_train_2[col].replace([None], np.nan)\n","  if (q1features_train_2[col].dtype == 'category' or q1features_train_2[col].dtype =='datetime64[ns]'):\n","    q1features_train_2[col] = q1features_train_2[col].fillna(q1features_train_2[col].mode()[0])\n","  if (q1features_train_2[col].dtype == 'Int64' or q1features_train_2[col].dtype == 'int64'):\n","    q1features_train_2[col] = q1features_train_2[col].astype('float64')\n","  if (q1features_train_2[col].dtype == 'float64'):\n","    q1features_train_2[col] = q1features_train_2[col].fillna(q1features_train_2[col].mean())"],"metadata":{"id":"8duQG0YX9_Hc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Normalization of validation set\n","for col in q1features_valid_2.columns.tolist():\n","  if (q1features_valid_2[col].dtype == 'Int64' or q1features_valid_2[col].dtype == 'int64' or q1features_valid_2[col].dtype == 'float64'):\n","    q1features_valid_2[col] = (q1features_valid_2[col] - min(q1features_train_2[col]))/(max(q1features_train_2[col]) - min(q1features_train_2[col]))"],"metadata":{"id":"GDOMb02t-ySX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Normalization of training set\n","for col in q1features_train_2.columns.tolist():\n","  if (q1features_train_2[col].dtype == 'Int64' or q1features_train_2[col].dtype == 'int64' or q1features_train_2[col].dtype == 'float64'):\n","    q1features_train_2[col] = (q1features_train_2[col] - min(q1features_train_2[col]))/(max(q1features_train_2[col]) - min(q1features_train_2[col]))"],"metadata":{"id":"3O7mvb7__aSD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#The SMOTE algorithm cannot handle datetime, so converting to number of\n","#days since January 1st, year one\n","for i in range(len(q1features_train_2['INTERVIEWDATE'])):\n","  q1features_train_2.loc[q1features_train_2.index[i], 'INTERVIEWDATE'] =  q1features_train_2.loc[q1features_train_2.index[i], 'INTERVIEWDATE'].toordinal()\n","\n","for i in range(len(q1features_valid_2['INTERVIEWDATE'])):\n","  q1features_valid_2.loc[q1features_valid_2.index[i], 'INTERVIEWDATE'] =  q1features_valid_2.loc[q1features_valid_2.index[i], 'INTERVIEWDATE'].toordinal()\n","\n","q1features_train_2['INTERVIEWDATE'] = q1features_train_2['INTERVIEWDATE'].astype('float64')\n","q1features_valid_2['INTERVIEWDATE'] = q1features_valid_2['INTERVIEWDATE'].astype('float64')"],"metadata":{"id":"kJp1yMCrAB_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Removing highly correlated variables\n","\n","#First selecting numeric attributes\n","numericVars = q1features_train_2.select_dtypes(include='float64')"],"metadata":{"id":"ouiy0YL8ApHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vif_data = pd.DataFrame()\n","vif_data[\"feature\"] = numericVars.columns\n","\n","# calculating VIF for each feature\n","vif_data[\"VIF\"] = [variance_inflation_factor(numericVars.values, i)\n","                          for i in range(len(numericVars.columns))]\n","\n","print(vif_data)"],"metadata":{"id":"v4wMomFABHg7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Iteratively removed attributes starting with highest VIF until all\n","#VIF values are below ten.\n","numericVars = numericVars.drop(['_AGE80', 'INTERVIEWDATE', 'HTM4'], axis=1)"],"metadata":{"id":"PCZMJZHlYJum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["q1features_train_2 = q1features_train_2.drop(['_AGE80', 'INTERVIEWDATE', 'HTM4'], axis=1)"],"metadata":{"id":"zrcMJljmYNAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#SMOTE Algorithm\n","from imblearn.over_sampling import SMOTE\n","sm = SMOTE(random_state = 2)\n","q1features_train_2_SM, q1target_train_2_SM = sm.fit_resample(q1features_train_2, q1target_train_2.ravel())"],"metadata":{"id":"9u_VRiivbN59"},"execution_count":null,"outputs":[]}]}